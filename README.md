# âœ‹ğŸ¤– Gesture-Based UAV Navigation Using Real-Time Vision and ArduPilot Simulation

> âœˆï¸ A Python-based drone control system that uses **MediaPipe hand tracking** and **DroneKit-ArduPilot simulation** to navigate UAVs through **fist gestures** detected from a live webcam feed, enabling intuitive, hands-free flight control.

---

### ğŸ§  Department of Computer Science and Business Systems  
**Mukesh Patel School of Technology Management and Engineering (NMIMS University, Mumbai)**  
**Authors:**  
- Rishi Kaushik  
- Diya Uday Nayak  
- Riya Bhalavat  

---

## ğŸ“– Overview
This project introduces a **gesture-controlled UAV navigation system** using **real-time vision-based fist detection**.  
By integrating **MediaPipe** for gesture tracking and **DroneKit-Python** with **ArduPilot SITL**, the system enables drones to turn left, right, or continue forward based on a userâ€™s hand position.  
This approach eliminates the need for handheld controllers, providing a **low-cost**, **intuitive**, and **hands-free** way to navigate drones.

---

## ğŸ”— Model File (Google Drive Link)
Due to GitHubâ€™s file size limitations, the trained model file has been uploaded to Google Drive.  
You can download it using the link below and place it in the project directory before running the code.

ğŸ‘‰ **Download Model:** [https://drive.google.com/file/d/1AQ3pEfdXgGr7AfehElrzMWBAK1bS7QNt/view?usp=drive_link]

---

## ğŸ¯ Objectives
- Enable **real-time gesture-based UAV control** using a live webcam feed.  
- Implement **DroneKit-ArduPilot** communication for guided-mode flight.  
- Achieve **smooth, stable navigation** without GPS jumps.  
- Create a **lightweight, portable system** for educational and practical UAV use.

---

## ğŸ§© Methodology

### 1. Video Frame Capture
- Live webcam input is streamed via **Iriun Webcam**, simulating mobile camera usage.

### 2. Frame Preprocessing
- Frames resized and converted using **OpenCV** to optimize for speed and clarity.

### 3. Gesture Recognition
- **MediaPipe Hand Tracking** detects hand landmarks.
- A rule-based classifier identifies **closed-fist gestures**.
- The camera frame is divided into zones:
  - **Left Zone â†’** Drone turns right  
  - **Center/Right Zone â†’** Drone turns left  
  - **No Fist Detected â†’** Drone continues forward

### 4. UAV Control
- **DroneKit-Python** commands UAV heading adjustments using MAVLink protocol.
- Operates in **GUIDED mode** for controlled and stable simulation.

### 5. Real-Time Loop
- Continuous 60-second control cycle:
  - Reads camera input â†’ Detects gesture â†’ Sends command â†’ Moves forward
- Ends with a **safe landing sequence**.

---

## ğŸ§± Software Stack

| Component | Description |
|------------|-------------|
| **Language** | Python 3.10 |
| **Gesture Detection** | MediaPipe |
| **Computer Vision** | OpenCV |
| **UAV Control** | DroneKit-Python + MAVLink |
| **Simulation** | ArduPilot SITL + MAVProxy |
| **Webcam Feed** | Iriun Webcam |
| **Environment** | Linux/Windows |

---

## ğŸ“¦ Dependencies

Install all dependencies with:

```bash
pip install dronekit pymavlink opencv-python mediapipe
